{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploring Decile Cords.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOL5SLi0k6cbKj85VQd++sZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaviShah1/COVID-19-Impact-On-Digital-Learning/blob/main/notebooks/try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDOc6L4a9hpz"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c 'cassava-leaf-disease-classification'\n",
        "! mkdir train\n",
        "! unzip /content/cassava-leaf-disease-classification.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAkwNmsxr6IE",
        "outputId": "04b8466d-6fa6-4ce8-87cf-340fc85cbff4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from albumentations import (\n",
        "    Compose, OneOf, Normalize, Resize, RandomCrop, HorizontalFlip, VerticalFlip, \n",
        "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
        "    IAAAdditiveGaussianNoise, Transpose\n",
        "    )\n",
        "from albumentations.pytorch import ToTensor\n",
        "from albumentations import ImageOnlyTransform\n",
        "\n",
        "import timm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U4jsPBGfghu",
        "outputId": "d74d19c4-fdeb-487f-9fef-6791b5bffd7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/train/train.csv\")"
      ],
      "metadata": {
        "id": "He5RjUKcghPY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits=5)\n",
        "for f, (t_, v_) in enumerate(kf.split(X=train_df, y=train_df['label'].values)):\n",
        "    train_df.loc[v_, 'fold'] = f\n",
        "\n",
        "train = train_df[train_df.fold!=0]\n",
        "valid = train_df[train_df.fold==0]"
      ],
      "metadata": {
        "id": "JK5v8h3fgjuN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    model = \"resnext50_32x4d\"\n",
        "    optimizer = \"AdamW\"\n",
        "    lr = 1e-5\n",
        "    weight_decay = 0.1\n",
        "    betas = (0.9, 0.999)\n",
        "    epochs = 3"
      ],
      "metadata": {
        "id": "SDLmX-ZEtaOD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeafDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.files = list(df[\"image_id\"])\n",
        "        self.labels = list(df[\"label\"])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_name = self.files[idx]\n",
        "        file_path = f\"/content/train/train_images/{file_name}\"\n",
        "        image = cv2.imread(file_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "        label = torch.tensor(self.labels[idx]).long()\n",
        "        return {\n",
        "            \"image\" : image,\n",
        "            \"label\" : label\n",
        "        }"
      ],
      "metadata": {
        "id": "L3IKMaFeiin4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = Compose([\n",
        "                        Resize(256, 256),\n",
        "                        Transpose(p=0.5),\n",
        "                        HorizontalFlip(p=0.5),\n",
        "                        VerticalFlip(p=0.5),\n",
        "                        ShiftScaleRotate(p=0.5),\n",
        "                        Normalize(\n",
        "                        mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225],\n",
        "                        ),\n",
        "                        ToTensor(),\n",
        "                    ])\n",
        "\n",
        "valid_transforms = Compose([\n",
        "                        Resize(256, 256),\n",
        "                        Normalize(\n",
        "                        mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225],\n",
        "                        ),\n",
        "                        ToTensor(),\n",
        "                    ])"
      ],
      "metadata": {
        "id": "TFW-2eqhiuSI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def criterion(outputs, labels):\n",
        "    return nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "def get_optimizer(model, lr, weight_decay, betas):\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(\n",
        "            nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "        {'params': [p for n, p in param_optimizer if any(\n",
        "            nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                      lr=lr,\n",
        "                      weight_decay=weight_decay,\n",
        "                      betas=betas,\n",
        "                     )\n",
        "    return optimizer\n",
        "\n",
        "def get_scheduler(optimizer, T_max=300):\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                           T_max=T_max)\n",
        "    return scheduler"
      ],
      "metadata": {
        "id": "hNezQQmdnby_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeafModel(nn.Module):\n",
        "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        n_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(n_features, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HV6dRAqArWuP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "bfC2eTlHsF51"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    losses = AverageMeter()\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        image = data['image'].to(device)\n",
        "        image.type(torch.FloatTensor)\n",
        "        targets = data['label'].to(device, dtype=torch.long)\n",
        "        \n",
        "        batch_size = image.size(0)\n",
        "\n",
        "        outputs = model(image)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        losses.update(loss.item(), outputs.size(0))\n",
        "        loss.backward()\n",
        "    \n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=losses.avg,\n",
        "                        LR=optimizer.param_groups[0]['lr'])\n",
        "    gc.collect()\n",
        "    \n",
        "    return losses.avg"
      ],
      "metadata": {
        "id": "jR3BvVwzsUyD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, optimizer, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    losses = AverageMeter()\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:        \n",
        "        image = data['image'].to(device)\n",
        "        image.type(torch.FloatTensor)\n",
        "        targets = data['label'].to(device, dtype=torch.long)\n",
        "        \n",
        "        batch_size = image.size(0)\n",
        "\n",
        "        outputs = model(image)\n",
        "        \n",
        "        loss = criterion(outputs, targets)\n",
        "        losses.update(loss.item(), outputs.size(0))\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Valid_Loss=losses.avg,\n",
        "                        LR=optimizer.param_groups[0]['lr'])   \n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return losses.avg"
      ],
      "metadata": {
        "id": "UgHuKVUws7nG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_fold(model, \n",
        "                   optimizer, \n",
        "                   scheduler, \n",
        "                   train_loader, \n",
        "                   valid_loader, \n",
        "                   fold):\n",
        "    \n",
        "    best_epoch_loss = np.inf\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "        gc.collect()\n",
        "        train_epoch_loss = train_one_epoch(model, \n",
        "                                           optimizer, \n",
        "                                           scheduler, \n",
        "                                           dataloader=train_loader, \n",
        "                                           device=device, \n",
        "                                           epoch=epoch)\n",
        "\n",
        "        val_epoch_loss = valid_one_epoch(model,\n",
        "                                         optimizer, \n",
        "                                         valid_loader, \n",
        "                                         device=device, epoch=epoch)\n",
        "        \n",
        "        if val_epoch_loss <= best_epoch_loss:\n",
        "            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
        "            best_epoch_loss = val_epoch_loss\n",
        "            \n",
        "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))"
      ],
      "metadata": {
        "id": "njSHlCqQtIvc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = LeafDataset(train, train_transforms)\n",
        "valid_ds = LeafDataset(valid, valid_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "yHWe3CbArOdU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeafModel()\n",
        "optimizer = get_optimizer(model, CFG.lr, CFG.weight_decay, CFG.betas)\n",
        "scheduler = get_scheduler(optimizer) "
      ],
      "metadata": {
        "id": "YTa0G6cNrxFd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_one_fold(model, optimizer, scheduler, train_loader, valid_loader, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tda7NvMwuQu6",
        "outputId": "2cb5ba82-c93f-4d8d-e712-a720be17c072"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [06:34<00:00,  2.71it/s, Epoch=0, LR=6.04e-6, Train_Loss=1.33]\n",
            "100%|██████████| 134/134 [00:56<00:00,  2.39it/s, Epoch=0, LR=6.04e-6, Valid_Loss=1.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 1.144788203284005)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [06:12<00:00,  2.87it/s, Epoch=1, LR=4.32e-7, Train_Loss=1.03]\n",
            "100%|██████████| 134/134 [00:54<00:00,  2.44it/s, Epoch=1, LR=4.32e-7, Valid_Loss=0.97]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (1.144788203284005 ---> 0.9696341545782357)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [06:12<00:00,  2.87it/s, Epoch=2, LR=2.06e-6, Train_Loss=0.932]\n",
            "100%|██████████| 134/134 [00:54<00:00,  2.44it/s, Epoch=2, LR=2.06e-6, Valid_Loss=0.881]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.9696341545782357 ---> 0.8807327479959648)\n",
            "Best Loss: 0.8807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqSzbdN7uqAV",
        "outputId": "28b26012-18d5-452d-e023-147265591a62"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 20 02:14:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    34W / 250W |   4225MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NSM2NAkw5Bur"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}